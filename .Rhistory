test_pred$fare_amount=predict(RF_model,test)
test_pred[1:10,]
train_index=sample(1:nrow(train),0.8*nrow(train))
x_train=train[train_index,]
x_test=train[-train_index,]
RF_model = randomForest(fare_amount ~.,data=x_train, ntree=200)
#Predicting validation
RF_predictions = predict(RF_model,x_test[,2:10])
regr.eval(x_test[,1],RF_predictions)
library("ggplot2")
library("Scale")
library("psych")
library("gplots")
library("DMwR")
library("corrgram")
library("dummies")
library("usdm")
rm(list=ls())
setwd("C:/Users/hp/Desktop/Project cap fare prediction")
getwd()
train=read.csv("train_cab.csv",header = T)
test=read.csv("test.csv",header = T)
# 1.passenger_count
length(unique(train$passenger_count))
train$passenger_count=round(train$passenger_count)
ggplot(train, aes_string(x=train$passenger_count))+geom_histogram(fill="red",color="black", binwidth = 100)+
xlab("passenger_count")+ylab("freq")+ggtitle("distribution for passenger_count")
# from test data we can see that passenger_count is integers between(1,6),Lets see how many values except these lies in our train dataset
#nrow(train[which(train$passenger_count<1),]) + nrow(train[which(train$passenger_count>6),])
# total 78 rows with unsensible values for passenger_count
# we can remove these values or we can replace them with NA then impute them using missing value imputattion methods
#Removing these Observations
#dim(train)
#train = train[-which(train$passenger_count < 1 ),]
#train = train[-which(train$passenger_count > 6),]
#dim(train)
#replacing Observations with NA
sum(is.na(train["passenger_count"]))
train$passenger_count[train$passenger_count<1]=NA
train$passenger_count[train$passenger_count>6]=NA
sum(is.na(train["passenger_count"]))
table(train$passenger_count)
train$passenger_count=round(train$passenger_count)
train$passenger_count=as.factor(train$passenger_count)
test$passenger_count=as.factor(test$passenger_count)
# 2) fare_amount
#Converting to Data type
train$fare_amount = as.numeric(as.character(train$fare_amount))
length(unique(train$fare_amount))
ggplot(train, aes_string(x=train$fare_amount))+geom_histogram(fill="red",color="black", binwidth = 1000)+
xlab("fare_amount")+ylab("freq")+ggtitle("distribution for fare_amount")
ggplot(train, aes_string(x=train$fare_amount))+geom_histogram(fill="red",color="black")+xlab("fare_amount")+ylab("freq")+
ggtitle("distribution for fare_amount")+ scale_x_continuous(breaks = seq(0,200, 20), lim = c(0, 200))
#Dealing with unsensible values of fare_amount
nrow(train[which(train$fare_amount<1),]) + nrow(train[which(train$fare_amount>200),])
sum(is.na(train$fare_amount))
train$fare_amount[train$fare_amount>200]=NA
train$fare_amount[train$fare_amount<1]=NA
sum(is.na(train$fare_amount))
length(unique(train$pickup_longitude))
length(unique(train$pickup_latitude))
length(unique(train$dropoff_longitude))
length(unique(train$dropoff_latitude))
par(mfrow=c(2,2))
plot(density(train$pickup_longitude),main="Distribution for pickup_longitude")
plot(density(train$pickup_latitude),main="Distribution for pickup_latitude")
plot(density(train$dropoff_longitude),main="Distribution for dropoff_longitude")
plot(density(train$dropoff_latitude),main="Distribution for dropoff_latitude")
nrow(train[which(train$pickup_latitude>90),])
sum(is.na(train$pickup_latitude))
train$pickup_latitude[train$pickup_latitude>90]=NA
sum(is.na(train$pickup_latitude))
nrow(train[which(train$dropoff_latitude < 39 | train$dropoff_latitude >42 |
train$pickup_latitude < 39 | train$pickup_latitude >42 |
train$dropoff_longitude < -75 | train$dropoff_longitude >-72|
train$pickup_longitude < -75 | train$pickup_longitude >-72),])
sum(is.na(train$pickup_latitude))
sum(is.na(train$pickup_longitude))
sum(is.na(train$dropoff_longitude))
sum(is.na(train$dropoff_latitude))
train$pickup_latitude[train$pickup_latitude < 39 ]=NA
train$pickup_latitude[train$pickup_latitude >42]=NA
train$dropoff_latitude[train$dropoff_latitude < 39]=NA
train$dropoff_latitude[train$dropoff_latitude >42]=NA
train$pickup_longitude[train$pickup_longitude < -75]=NA
train$pickup_longitude[train$pickup_longitude >-72]=NA
train$dropoff_longitude[train$dropoff_longitude < -75]=NA
train$dropoff_longitude[train$dropoff_longitude >-72]=NA
sum(is.na(train$pickup_latitude))
sum(is.na(train$pickup_longitude))
sum(is.na(train$dropoff_longitude))
sum(is.na(train$dropoff_latitude))
par(mfrow=c(2,2))
plot(density(train$pickup_longitude),main="Distribution for pickup_longitude")
plot(density(train$pickup_latitude),main="Distribution for pickup_latitude")
plot(density(train$dropoff_longitude),main="Distribution for dropoff_longitude")
plot(density(train$dropoff_latitude),main="Distribution for dropoff_latitude")
#Lets plot the scatter plot for pickup location and dropoff location to understand the data more clearly
ggplot(train,aes_string(x=train$pickup_latitude,y=train$pickup_longitude))+geom_point(color="blue")+xlab("pickup_latitude")+
ylab("pickup_longitude")+theme_bw()+ggtitle("pickup_location")
ggplot(train,aes_string(x=train$dropoff_latitude,y=train$dropoff_longitude))+geom_point(color="red")+xlab("dropoff_latitude")+
ylab("dropoff_longitude")+theme_bw()+ggtitle("dropoff_location")
missing_value=data.frame(apply(train,2,function(x)(sum(is.na(x)))))
missing_value$variables=row.names(missing_value)
row.names(missing_value)= NULL
names(missing_value)[1]="missing_%"
missing_value=missing_value[,c(2,1)]
missing_value$`missing_%`=(missing_value$`missing_%`/nrow(train)*100)
missing_value=missing_value[order(-missing_value$`missing_%`),]
View(missing_value)
#What we can do is we can drop these values or we can imputate them using missing value imputation method
df1=train
df=df1
df$passenger_count[1000]
df$passenger_count[1000]=NA
df$passenger_count[1000]
table(df$passenger_count)
df$passenger_count[1000]=NA
df = knnImputation(df, k = 9)
df$passenger_count[1000]
sum(is.na(df))
df=df1
sum(is.na(df))
df$fare_amount[100]
df$fare_amount[100]=NA
df$fare_amount[100]
summary(df$fare_amount)
df = knnImputation(df, k = 9)
df$fare_amount[100]
df=df1
df[1000,]
df$pickup_latitude[1000]=NA
df$pickup_longitude[1000]=NA
df$dropoff_latitude[1000]=NA
df$dropoff_longitude[1000]=NA
df[1000,]
df$pickup_latitude[is.na(df$pickup_latitude)]=mean(df$pickup_latitude , na.rm=T)
df$pickup_longitude[is.na(df$pickup_longitude)]=mean(df$pickup_longitude, na.rm=T)
df$dropoff_latitude[is.na(df$dropoff_latitude)]=mean(df$dropoff_latitude , na.rm=T)
df$dropoff_longitude[is.na(df$dropoff_longitude)]=mean(df$dropoff_longitude , na.rm=T)
df[1000,]
df=df1
df[1000,]
df$pickup_latitude[1000]=NA
df$pickup_longitude[1000]=NA
df$dropoff_latitude[1000]=NA
df$dropoff_longitude[1000]=NA
df[1000,]
df$pickup_latitude[is.na(df$pickup_latitude)]=median(df$pickup_latitude , na.rm=T)
df$pickup_longitude[is.na(df$pickup_longitude)]=median(df$pickup_longitude, na.rm=T)
df$dropoff_latitude[is.na(df$dropoff_latitude)]=median(df$dropoff_latitude , na.rm=T)
df$dropoff_longitude[is.na(df$dropoff_longitude)]=median(df$dropoff_longitude , na.rm=T)
df[1000,]
df=df1
df[1000,]
df$pickup_latitude[1000]=NA
df$pickup_longitude[1000]=NA
df$dropoff_latitude[1000]=NA
df$dropoff_longitude[1000]=NA
df[1000,]
df = knnImputation(df, k = 9)
df[1000,]
sum(is.na(train$pickup_latitude))
sum(is.na(train$pickup_longitude))
sum(is.na(train$dropoff_latitude))
sum(is.na(train$dropoff_longitude))
train$pickup_latitude[is.na(train$pickup_latitude)]=median(train$pickup_latitude, na.rm=T)
train$pickup_longitude[is.na(train$pickup_longitude)]=median(train$pickup_longitude, na.rm=T)
train$dropoff_latitude[is.na(train$dropoff_latitude)]=median(train$dropoff_latitude, na.rm = T)
train$dropoff_latitude[is.na(train$dropoff_latitude)]=mean(train$dropoff_latitude, na.rm =T)
sum(is.na(train$pickup_latitude))
sum(is.na(train$pickup_longitude))
sum(is.na(train$dropoff_latitude))
sum(is.na(train$dropoff_longitude))
train=knnImputation(train, k=9)
sum(is.na(train))
par(mfrow=c(2,2))
plot(density(train$pickup_longitude),main="Distribution for pickup_longitude")
plot(density(train$pickup_latitude),main="Distribution for pickup_latitude")
plot(density(train$dropoff_longitude),main="Distribution for dropoff_longitude")
plot(density(train$dropoff_latitude),main="Distribution for dropoff_latitude")
#lets also see how fare_amount is varying with latitude and longitude
ggplot(train,aes_string(x=train$pickup_latitude,y=train$fare_amount))+geom_point(color="blue")+xlab("pickup_latitude")+
ylab("fare_amount")+theme_bw()+ggtitle("variation in fare_amount with pickup_latitude")
#Lets plot the scatter plot for pickup location and dropoff location to understand the data more clearly
ggplot(train,aes_string(x=train$pickup_latitude,y=train$pickup_longitude))+geom_point(color="blue")+xlab("pickup_latitude")+
ylab("pickup_longitude")+theme_bw()+ggtitle("pickup_location")
ggplot(train,aes_string(x=train$dropoff_latitude,y=train$dropoff_longitude))+geom_point(color="red")+xlab("dropoff_latitude")+
ylab("dropoff_longitude")+theme_bw()+ggtitle("dropoff_location")
#lets also see how fare_amount is varying with latitude and longitude
ggplot(train,aes_string(x=train$pickup_latitude,y=train$fare_amount))+geom_point(color="blue")+xlab("pickup_latitude")+
ylab("fare_amount")+theme_bw()+ggtitle("variation in fare_amount with pickup_latitude")
ggplot(train,aes_string(x=train$pickup_latitude,y=train$fare_amount))+geom_point(color="blue")+xlab("pickup_longitude")+
ylab("fare_amount")+theme_bw()+ggtitle("variation in fare_amount with pickup_longitude")
ggplot(train,aes_string(x=train$dropoff_latitude,y=train$fare_amount))+geom_point(color="blue")+xlab("dropoff_latitude")+
ylab("fare_amount")+theme_bw()+ggtitle("variation in fare_amount with dropoff_latitude")
ggplot(train,aes_string(x=train$dropoff_longitude,y=train$fare_amount))+geom_point(color="blue")+xlab("dropoff_longitude")+
ylab("fare_amount")+theme_bw()+ggtitle("variation in fare_amount with dropoff_longitude")
ggplot(train,aes_string(x=train$pickup_longitude,y=train$fare_amount))+geom_point(color="blue")+xlab("pickup_longitude")+
ylab("fare_amount")+theme_bw()+ggtitle("variation in fare_amount with pickup_longitude")
ggplot(train,aes_string(x=train$dropoff_latitude,y=train$fare_amount))+geom_point(color="red")+xlab("dropoff_latitude")+
ylab("fare_amount")+theme_bw()+ggtitle("variation in fare_amount with dropoff_latitude")
ggplot(train,aes_string(x=train$dropoff_longitude,y=train$fare_amount))+geom_point(color="red")+xlab("dropoff_longitude")+
ylab("fare_amount")+theme_bw()+ggtitle("variation in fare_amount with dropoff_longitude")
train$pickup_datetime= strptime(train$pickup_datetime,"%Y-%m-%d %H:%M:%S")
train$year=as.factor(format(train$pickup_datetime,"%Y"))
train$month=as.factor(format(train$pickup_datetime,"%m"))
train$dayofweek = as.factor(format(train$pickup_datetime,"%u"))# Monday = 1
train$Hour=as.factor(format(train$pickup_datetime,"%H"))
test$pickup_datetime= strptime(test$pickup_datetime,"%Y-%m-%d %H:%M:%S")
test$year=as.factor(format(test$pickup_datetime,"%Y"))
test$month=as.factor(format(test$pickup_datetime,"%m"))
test$dayofweek = as.factor(format(test$pickup_datetime,"%u"))# Monday = 1
test$Hour=as.factor(format(test$pickup_datetime,"%H"))
#lets check for missing values
sum(is.na(train))
train=train[-which(is.na(train$pickup_datetime)),]
sum(is.na(train))
table(train$year)
table(train$month)
table(train$dayofweek)
table(train$Hour)
#Dropping the variable we used to create features
train = subset(train,select = -c(pickup_datetime))
test = subset(test,select = -c(pickup_datetime))
barplot(table(train$year),xlab = "year", ylab = "No. of Trips", main = "Trips per year")
barplot(table(train$month),xlab = "month", ylab = "No. of Trips",main = "Trips per month")
barplot(table(train$Hour),xlab = "hour",ylab = "No. of Trips", main = "Trips per hour")
barplot(table(train$dayofweek),xlab = "dayofweek",ylab = "No. of Trips", main = "Trips per dayofweek")
#Lets plot some visualization to find how the fare_amount is varing with these new features
# A) avg fare_amount with year
ggplot(train,aes_string(x=train$year, y=train$fare_amount, fill=train$year))+geom_bar(stat = "summary", fun.y="mean")+
xlab("year")+ylab("avg_fare")+ggtitle("variation in avg_fare with year")
# we can see from the above bar plot that avg_fare is increasing with year
# B) avg fare_amount with month
ggplot(train,aes_string(x=train$month, y=train$fare_amount, fill=train$month))+geom_bar(stat = "summary", fun.y="mean")+
xlab("month")+ylab("avg_fare")+ggtitle("variation in avg_fare with month")
# from month 2 to 5 avgfare_amount is higher and it is again higher from month 8 to 12
# c) avg fare_amount with hour
ggplot(train,aes_string(x=train$Hour, y=train$fare_amount, fill=train$Hour))+geom_bar(stat = "summary", fun.y="mean")+
xlab("Hour")+ylab("avg_fare")+ggtitle("variation in avg_fare with Hour")
# we can see from plot that fare is higher for rides between 12AM to 5AM and 2PM to 4PM.
# D) avg fare_amount with dayofweek
ggplot(train,aes_string(x=train$dayofweek, y=train$fare_amount, fill=train$dayofweek))+geom_bar(stat = "summary", fun.y="mean")+
xlab("dayofweek")+ylab("avg_fare")+ggtitle("variation in avg_fare with dayofweek")
for (i in 1: nrow(train)){
radius=6378.1
diff_lat_train=(train$dropoff_latitude-train$pickup_latitude)*pi/180
diff_long_train=(train$dropoff_longitude-train$pickup_longitude)*pi/180
a_train= (sin(diff_lat_train/2)*sin(diff_lat_train/2))+
(cos((train$pickup_latitude)*pi/180)*cos((train$dropoff_latitude)*pi/180)*
sin(diff_long_train/2)*sin(diff_long_train/2))
c_train=2*atan2((a_train^0.5),((1-a_train)^0.5))
train$trip_distance= radius*c_train
}
dim(train)
train$trip_distance=round(train$trip_distance, digits = 3)
for (i in 1: nrow(test)){
radius=6378.1
diff_lat=(test$dropoff_latitude-test$pickup_latitude)*pi/180
diff_long=(test$dropoff_longitude-test$pickup_longitude)*pi/180
a= (sin(diff_lat/2)*sin(diff_lat/2))+ (cos((test$pickup_latitude)*pi/180)*cos((test$dropoff_latitude)*pi/180)*
sin(diff_long/2)*sin(diff_long/2))
c=2*atan2((a^0.5),((1-a)^0.5))
test$trip_distance= radius*c
}
dim(test)
test$trip_distance=round(test$trip_distance, digits = 3)
par(mfrow=c(1,1))
plot(density(train$trip_distance),main="Distribution for trip_distance")
summary(train$trip_distance)
ggplot(train,aes_string(x=train$trip_distance,y=train$fare_amount))+geom_point(color="blue")+xlab("trip_distance")+
ylab("fare_amount")+theme_bw()+ggtitle("fare_amount vs trip_distance")
#Lets plot correlation plot for numeric variables
numeric_index=sapply(train,is.numeric)
numeric_data=train[,numeric_index]
numeric_index
numeric=colnames(numeric_data)
corrgram(train[,numeric],order=F,upper.panel = panel.pie,main="correlation plot")
factor_index=sapply(train, is.factor)
factor_data=train[,factor_index]
factors=colnames(factor_data)
print(chisq.test(train$passenger_count,train$year))
print(chisq.test(train$passenger_count,train$month))
print(chisq.test(train$passenger_count,train$Hour))
print(chisq.test(train$passenger_count,train$dayofweek))
print(chisq.test(train$year,train$month))
print(chisq.test(train$year,train$Hour))
print(chisq.test(train$year,train$dayofweek))
print(chisq.test(train$month,train$Hour))
print(chisq.test(train$month,train$dayofweek))
print(chisq.test(train$Hour,train$dayofweek))
aov_results = aov(fare_amount ~ passenger_count + Hour +dayofweek + month +year,data = train)
summary(aov_results)
train = subset(train,select=-dayofweek)
test = subset(test,select=-dayofweek)
par(mfrow=c(2,3))
plot(density(train$pickup_longitude),main="Distribution for pickup_longitude")
plot(density(train$pickup_latitude),main="Distribution for pickup_latitude")
plot(density(train$dropoff_longitude),main="Distribution for dropoff_longitude")
plot(density(train$dropoff_latitude),main="Distribution for dropoff_latitude")
plot(density(train$fare_amount),main="Distribution for fare_amount")
plot(density(train$trip_distance),main="Distribution for trip_distance")
cnames=list("pickup_latitude","pickup_longitude","dropoff_latitude","dropoff_longitude","trip_distance")
df2=train
for (i in cnames){
print(i)
train[,i] = (train[,i] - min(train[,i]))/(max(train[,i] - min(train[,i])))
}
for (i in cnames){
print(i)
test[,i] = (test[,i] - min(test[,i]))/(max(test[,i] - min(test[,i])))
}
train_index=sample(1:nrow(train),0.8*nrow(train))
x_train=train[train_index,]
x_test=train[-train_index,]
vif(x_train[,-1])
vifcor(x_train[,numeric],th=0.9)
#Liner Regression model
lm_model=lm(fare_amount~.,data = x_train)
summary(lm_model)
lm_predictions = predict(lm_model,x_test[,2:10])
regr.eval(x_test[,1],lm_predictions)
library("rpart")
#_______________Decision Tree_________________#
DT_model = rpart(fare_amount ~ ., data = x_train, method = "anova")
DT_model
DT_predictions = predict(DT_model, x_test[,2:10])
regr.eval(x_test[,1],DT_predictions)
library("randomForest")
#______________Random Forest_______________#
RF_model = randomForest(fare_amount ~.,data=x_train, ntree=200)
par(mfrow=c(1,1))
varImpPlot(RF_model,sort = TRUE)
#Predicting validation
RF_predictions = predict(RF_model,x_test[,2:10])
regr.eval(x_test[,1],RF_predictions)
#______________Random Forest_______________#
RF_model = randomForest(fare_amount ~.,data=x_train, ntree=300)
#Predicting validation
RF_predictions = predict(RF_model,x_test[,2:10])
regr.eval(x_test[,1],RF_predictions)
#prediction on actual test data
test_pred=test
test_pred$fare_amount=predict(RF_model,test)
test_pred[1:10,]
#Writting csv file for predicted values
write.csv(test_pred,"test_predicted_R.csv",row.names = F)
View(missing_value)
#______________Random Forest_______________#
RF_model = randomForest(fare_amount ~.,data=x_train, ntree=300)
library("ggplot2")
library("Scale")
library("psych")
library("gplots")
library("DMwR")
library("corrgram")
library("dummies")
library("usdm")
library("rpart")
library("randomForest")
#______________Random Forest_______________#
RF_model = randomForest(fare_amount ~.,data=x_train, ntree=300)
#Predicting validation
RF_predictions = predict(RF_model,x_test[,2:10])
regr.eval(x_test[,1],RF_predictions)
#_______________Decision Tree_________________#
DT_model = rpart(fare_amount ~ ., data = x_train, method = "anova")
DT_model
DT_predictions = predict(DT_model, x_test[,2:10])
regr.eval(x_test[,1],DT_predictions)
#Liner Regression model
lm_model=lm(fare_amount~.,data = x_train)
summary(lm_model)
lm_predictions = predict(lm_model,x_test[,2:10])
regr.eval(x_test[,1],lm_predictions)
#_______________Dividing in Train and Test data_______________#
train_index=sample(1:nrow(train),0.8*nrow(train))
x_train=train[train_index,]
x_test=train[-train_index,]
#Liner Regression model
lm_model=lm(fare_amount~.,data = x_train)
summary(lm_model)
lm_predictions = predict(lm_model,x_test[,2:10])
regr.eval(x_test[,1],lm_predictions)
#_______________Decision Tree_________________#
DT_model = rpart(fare_amount ~ ., data = x_train, method = "anova")
DT_model
DT_predictions = predict(DT_model, x_test[,2:10])
regr.eval(x_test[,1],DT_predictions)
#______________Random Forest_______________#
RF_model = randomForest(fare_amount ~.,data=x_train, ntree=300)
varImpPlot(DT_model, sort = TRUE)
plot(feature_importance(DT_model))
plot(DT_model)
plot(varImp(DT_model))
DT_model
#Predicting validation
RF_predictions = predict(RF_model,x_test[,2:10])
regr.eval(x_test[,1],RF_predictions)
x_train$pickup_longitude.importance
x_train$trip_disyance.importance
#_______________Decision Tree_________________#
DT_model = rpart(fare_amount ~ ., data = x_train, method = "anova")
DT_model
x_train$trip_disyance.importance
summary(DT_model)
plot(importance(DT_model))
plot(Importance(DT_model))
plot(DT_model)
test_copy=test
#prediction on actual test data
test_copy$fare_amount=predict(RF_model,test)
library("randomForest")
#______________Random Forest_______________#
RF_model = randomForest(fare_amount ~.,data=x_train, ntree=300)
#Predicting validation
RF_predictions = predict(RF_model,x_test[,2:10])
regr.eval(x_test[,1],RF_predictions)
library("rpart")
#Predicting validation
RF_predictions = predict(RF_model,x_test[,2:10])
regr.eval(x_test[,1],RF_predictions)
library("ggplot2")
library("Scale")
library("psych")
library("gplots")
library("DMwR")
library("corrgram")
library("dummies")
library("usdm")
library("rpart")
library("randomForest")
regr.eval(x_test[,1],RF_predictions)
# so from above we can see the lowest value of RMSE we get is 4.65 i.e. for Random forest hence we select Random
#    forest algorithm for this problem
R2 = 1 - (sum((x_test[,1]-RF_predicted)^2)/sum((x_test[,1]-mean(x_test$fare_amount))^2))
# so from above we can see the lowest value of RMSE we get is 4.65 i.e. for Random forest hence we select Random
#    forest algorithm for this problem
R2 = 1 - (sum((x_test[,1]-RF_predictions)^2)/sum((x_test[,1]-mean(x_test$fare_amount))^2))
R2=0
for (i in 1:nwor(x_train)){
R2 = R2+(((x_test[i,1]-RF_predictions[i])^2)/sum((x_test[i,1]-mean(x_test$fare_amount))^2))
}
for (i in 1:nrow(x_train)){
R2 = R2+(((x_test[i,1]-RF_predictions[i])^2)/sum((x_test[i,1]-mean(x_test$fare_amount))^2))
}
for (i in 1:nrow(x_train)){
R2 = R2+(((x_test[i,1]-RF_predictions[i])^2)/sum((x_test[i,1]-mean(x_test$fare_amount))^2))
}
for (i in 1:nrow(x_train)){
R2 = R2+(((x_test[i,1]-RF_predictions[i])^2)/sum((x_test[i,1]-mean(x_test$fare_amount))^2))
}
for (i in 1:nrow(x_train)){
R2 = R2+(((x_test[i,1]-RF_predictions[i])^2)/sum((x_test[i,1]-mean(x_test$fare_amount))^2))
}
View(x_test)
R2 = 1 - (sum((x_test[,1]-RF_predictions)^2)/sum((x_test[,1]-mean(x_test$fare_amount))^2))
mean(x_test$fare_amount)
rsq.rpart(DT_model)
R2=1-((sum(x_test[,1]-RF_predictions)^2)/(sum(x_train[,1]-mean(x_test$fare_amount))))
R2=1-((sum(x_test[,1]-RF_predictions)^2)/(sum(x_test[,1]-mean(x_test$fare_amount))))
R2=1-((sum((x_test[,1]-RF_predictions)^2))/(sum((x_test[,1]-mean(x_test$fare_amount))^2)))
x=1- (21.63/var(x_test$fare_amount))
x=1- (21.63/var(RF_predictions))
RX=1- (15.38/var(x_test$fare_amount))
R2 = 1 - (sum((x_test[,1]-RF_predictions)^2)/sum((x_test[,1]-mean(x_test$fare_amount))^2))
cor(RF_predictions, x_test[, 1])^2
R2=cor(RF_predictions, x_test[, 1])^2
test_copy=test
sum(is.na(train))
dim(train)
R2=cor(RF_predictions, x_test[, 1])^2
regr.eval(x_test[,1],RF_predictions)
library("ggplot2")
library("Scale")
library("psych")
library("gplots")
library("DMwR")
library("corrgram")
library("dummies")
library("usdm")
library("rpart")
library("randomForest")
DT_model = rpart(fare_amount ~ ., data = x_train, method = "anova")
DT_model
rsq.rpart(DT_model)
DT_predictions = predict(DT_model, x_test[,2:10])
regr.eval(x_test[,1],DT_predictions)
#Liner Regression model
lm_model=lm(fare_amount~.,data = x_train)
summary(lm_model)
lm_predictions = predict(lm_model,x_test[,2:10])
regr.eval(x_test[,1],lm_predictions)
#______________Random Forest_______________#
RF_model = randomForest(fare_amount ~.,data=x_train, ntree=300)
#Lets do Chi-square test for Categorical variables
rm(factor_index)
#Lets do Chi-square test for Categorical variables
rm(factor_data)
#Lets do Chi-square test for Categorical variables
rm(factors)
print(chisq.test(train$passenger_count,train$year))
print(chisq.test(train$passenger_count,train$month))
print(chisq.test(train$passenger_count,train$Hour))
print(chisq.test(train$passenger_count,train$dayofweek))
print(chisq.test(train$year,train$month))
print(chisq.test(train$year,train$Hour))
print(chisq.test(train$year,train$dayofweek))
print(chisq.test(train$month,train$Hour))
print(chisq.test(train$month,train$dayofweek))
print(chisq.test(train$Hour,train$dayofweek))
